{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anti-Money Laundering and Fraud Prediction\n",
    "This is a breakdown of the overall models that can be developed to make AI models to predict and detect money-laundering or fraud within financial datasets.\n",
    "Data sources for these datasets come from sources on Kaggle:\n",
    "- [Credit Card Fraud Detection | Kaggle](https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud?datasetId=310&sortBy=voteCount)\n",
    "- [Fake Bills | Kaggle](\"https://www.kaggle.com/datasets/alexandrepetit881234/fake-bills\")\n",
    "\n",
    "These data sets contain various amounts of data dating till 2013, with various levels of information that is captured from financial entities."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packages to install for below\n",
    "> Make sure pip is up to date for these packages to install\n",
    ">> `python.exe -m pip install --upgrade pip`\n",
    "\n",
    "> To install the SciKit (sklearn) packages use the below command:\n",
    ">> `pip install scikit-learn`\n",
    "\n",
    "> To install Seaborn packages use the below command:\n",
    ">> `pip install seaborn`\n",
    "\n",
    "> To install the Plotly packages use the below command:\n",
    ">> `pip install plotly`\n",
    "\n",
    "NOTE: You will need to download Python version 3.11 from the Microsoft Store for this to work"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Library Imports\n",
    "To start the overall work click play on the play button for the packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\devlap02\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.24.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 23.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m get_ipython()\u001b[39m.\u001b[39msystem(\u001b[39m'\u001b[39m\u001b[39m{sys.executable}\u001b[39;00m\u001b[39m -m pip install numpy\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m \u001b[39m# linear algebra breakdown\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m \u001b[39m# data processing, CSV files input/output\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m \u001b[39m# graph plotting\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mseaborn\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39msns\u001b[39;00m \n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script f2py.exe is installed in 'c:\\Users\\DevLap02\\AppData\\Local\\Programs\\Python\\Python311\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 23.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numpy\n",
      "  Using cached numpy-1.24.2-cp311-cp311-win_amd64.whl (14.8 MB)\n",
      "Installing collected packages: numpy\n",
      "Successfully installed numpy-1.24.2\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install numpy\n",
    "\n",
    "import numpy as np # linear algebra breakdown\n",
    "import pandas as pd # data processing, CSV files input/output\n",
    "import matplotlib.pyplot as plt # graph plotting\n",
    "import seaborn as sns \n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "from numpy import percentile\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from scipy import stats\n",
    "from scipy.stats import trim_mean\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import average_precision_score"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset files"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above components you will then be able to import the different files that are needing to be analysed with Pandas.\n",
    "Pandas will be able to pull in the different files, for example with this work from Github."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#urls = [\"https://github.com/jono120/fictional-octo-potato/raw/main/transaction_data/fake_bills.csv\", \"https://github.com/Jono120/fictional-octo-potato/tree/main/transaction_data/bank.csv\", \"https://github.com/Jono120/fictional-octo-potato/tree/main/transaction_data/train_trd.csv\"]\n",
    "#df = pd.read_csv(\"https://github.com/jono120/fictional-octo-potato/raw/main/transaction_data/fake_bills.csv\")\n",
    "#df = pd.read_csv(\"https://github.com/Jono120/fictional-octo-potato/tree/main/transaction_data/bank.csv\")\n",
    "#df = pd.read_csv(\"https://github.com/Jono120/fictional-octo-potato/tree/main/transaction_data/train_trd.csv\")\n",
    "\n",
    "#dfs = [pd.read_csv(url) for url in urls]\n",
    "#df = pd.concat(dfs)\n",
    "#print(df.head())\n",
    "#df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"https://github.com/jono120/fictional-octo-potato/raw/main/transaction_data/fake_bills.csv\", sep = ';')\n",
    "\n",
    "df_false = df.loc[df['is_genuine']==False]\n",
    "df_true = df.loc[df['is_genuine']==True]\n",
    "df_true = df_true.fillna(df_true.median())\n",
    "df_false = df_false.fillna(df_false.median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Shape of dataset:\", df.shape)\n",
    "print(\"Overview of the data:\" )\n",
    "print(df.head())\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_true.describe().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_false.describe().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catfeat = []\n",
    "numfeat = []\n",
    "\n",
    "for i in df.columns:\n",
    "    if(df[i].dtypes == 'objects'): catfeat.append(i)\n",
    "    else:\n",
    "        numfeat.append(i)\n",
    "print(f'The number of Objects Features : {len(catfeat)}')\n",
    "print(f'The number of Numerical Features : {len(numfeat)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Number of missing values : {df.isnull().sum().sum()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "namedfeat = ['Time', 'Amount']\n",
    "for i in df[namedfeat]:\n",
    "    if(df[i].duplicated().sum() > 0): print(f'{i} Number of Duplicatied : {df[i].duplicated().sum()}') "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2c411529d52bd385a0c5cc81dc7774bf283ab520578901012898b94c5b56fc2a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

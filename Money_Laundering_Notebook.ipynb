{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anti-Money Laundering and Fraud Prediction\n",
    "This is a breakdown of the overall models that can be developed to make AI models to predict and detect money-laundering or fraud within financial datasets.\n",
    "Data sources for these datasets come from sources on Kaggle:\n",
    "- [Credit Card Fraud Detection | Kaggle](https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud?datasetId=310&sortBy=voteCount)\n",
    "- [Fake Bills | Kaggle](\"https://www.kaggle.com/datasets/alexandrepetit881234/fake-bills\")\n",
    "\n",
    "These data sets contain various amounts of data dating till 2013, with various levels of information that is captured from financial entities."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packages to install for below\n",
    "Make sure pip is up to date for these packages to install\n",
    "```\n",
    "python.exe -m pip install --upgrade pip\n",
    "```\n",
    "\n",
    "To install the SciKit (sklearn) packages use the below command:\n",
    "```\n",
    "pip install scikit-learn\n",
    "```\n",
    "\n",
    "To install Seaborn packages use the below command:\n",
    "```\n",
    "pip install seaborn\n",
    "```\n",
    "\n",
    "To install the Plotly packages use the below command:\n",
    "```\n",
    "pip install plotly\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Library Imports\n",
    "To start the overall work click play on the play button for the packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra breakdown\n",
    "import pandas as pd # data processing, CSV files input/output\n",
    "import matplotlib.pyplot as plt # graph plotting\n",
    "import seaborn as sns \n",
    "import warnings\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "from numpy import percentile\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset files"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above components you will then be able to import the different files that are needing to be analysed with Pandas.\n",
    "Pandas will be able to pull in the different files, for example with this work from Github."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#urls = [\"https://github.com/jono120/fictional-octo-potato/raw/main/transaction_data/fake_bills.csv\", \"https://github.com/Jono120/fictional-octo-potato/tree/main/transaction_data/bank.csv\", \"https://github.com/Jono120/fictional-octo-potato/tree/main/transaction_data/train_trd.csv\"]\n",
    "#df = pd.read_csv(\"https://github.com/jono120/fictional-octo-potato/raw/main/transaction_data/fake_bills.csv\")\n",
    "#df = pd.read_csv(\"https://github.com/Jono120/fictional-octo-potato/tree/main/transaction_data/bank.csv\")\n",
    "#df = pd.read_csv(\"https://github.com/Jono120/fictional-octo-potato/tree/main/transaction_data/train_trd.csv\")\n",
    "\n",
    "#dfs = [pd.read_csv(url) for url in urls]\n",
    "#df = pd.concat(dfs)\n",
    "#print(df.head())\n",
    "#df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full = pd.read_csv(\"https://github.com/jono120/fictional-octo-potato/raw/main/transaction_data/fake_bills.csv\", sep = ';')\n",
    "\n",
    "df_false = df_full.loc[df_full['is_genuine']==False]\n",
    "df_true = df_full.loc[df_full['is_genuine']==True]\n",
    "df_true = df_true.fillna(df_true.median())\n",
    "df_false = df_false.fillna(df_false.median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Shape of dataset:\", df_full.shape)\n",
    "print(\"Overview of the data:\" )\n",
    "print(df.head())\n",
    "df_full.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_true.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_false.describe()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2c411529d52bd385a0c5cc81dc7774bf283ab520578901012898b94c5b56fc2a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

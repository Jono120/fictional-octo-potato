{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anti-Money Laundering and Fraud Prediction\n",
    "This is a breakdown of the overall models that can be developed to make AI models to predict and detect money-laundering or fraud within financial datasets.\n",
    "Data sources for these datasets come from sources on Kaggle:\n",
    "- [IBM Transactions for Anti Money Laundering (AML) | Kaggle](https://www.kaggle.com/code/alexisbcook/creating-your-own-notebooks/tutorial)\n",
    "\n",
    "These data sets contain various amounts of data dating till 2013, with various levels of information that is captured from financial entities.\n",
    "\n",
    "@Article{Hunter:2007,\n",
    "  Author    = {Hunter, J. D.},\n",
    "  Title     = {Matplotlib: A 2D graphics environment},\n",
    "  Journal   = {Computing in Science \\& Engineering},\n",
    "  Volume    = {9},\n",
    "  Number    = {3},\n",
    "  Pages     = {90--95},\n",
    "  abstract  = {Matplotlib is a 2D graphics package used for Python for\n",
    "  application development, interactive scripting, and publication-quality\n",
    "  image generation across user interfaces and operating systems.},\n",
    "  publisher = {IEEE COMPUTER SOC},\n",
    "  doi       = {10.1109/MCSE.2007.55},\n",
    "  year      = 2007\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packages to install for below\n",
    "> Make sure pip is up to date for these packages to install\n",
    ">> `python.exe -m pip install --upgrade pip`\n",
    "\n",
    "> To install the SciKit (sklearn) packages use the below command:\n",
    ">> `pip install scikit-learn`\n",
    "\n",
    "> To install Seaborn packages use the below command:\n",
    ">> `pip install seaborn`\n",
    "\n",
    "> To install the Plotly packages use the below command:\n",
    ">> `pip install plotly`\n",
    "\n",
    "NOTE: You will need to download Python version 3.11 from the Microsoft Store for this to work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --upgrade pip\n",
    "%pip install scikit-learn\n",
    "%pip install seaborn\n",
    "%pip install plotly\n",
    "%pip install tensorflow\n",
    "%pip install pandas\n",
    "%pip install pyodbc\n",
    "%pip install openpyxl\n",
    "%pip install nbformat"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Library Imports\n",
    "To start the overall work click play on the play button for the packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import numpy as np # linear algebra breakdown\n",
    "import pandas as pd # data processing, CSV files input/output\n",
    "import matplotlib.pyplot as plt # graph plotting\n",
    "import seaborn as sns \n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.offline import iplot\n",
    "\n",
    "from numpy import percentile\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from scipy import stats\n",
    "from scipy.stats import trim_mean\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset files"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above components you will then be able to import the different files that are needing to be analysed with Pandas.\n",
    "Pandas will be able to pull in the different files, for example with this work from Github."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#url ='https://onedrive.live.com/download?cid=4A3B8562A2CB78B3&resid=4A3B8562A2CB78B3%21158025&authkey=ACHHRI10a-phyio&em=2'\n",
    "url ='https://onedrive.live.com/download?cid=4A3B8562A2CB78B3&resid=4A3B8562A2CB78B3%21158163&authkey=AFMTDEy7Ff3oCL8'\n",
    "#url ='https://onedrive.live.com/download?cid=4A3B8562A2CB78B3&resid=4A3B8562A2CB78B3%21158165&authkey=APswAhpzUuOs4KQ'\n",
    "\n",
    "#df = pd.read_excel(url)\n",
    "df = pd.read_csv(url)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview of dataset\n",
    "This shows the breakdown of the dataset and shows what is visible in the information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Shape of dataset:\", df.shape)\n",
    "print(\"Overview of the data:\")\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Is Laundering'] = df['Is Laundering'].replace({'Yes': 1, 'No':0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subset = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Data types of columns\", df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Description of the dataset:\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scans the data to search the percentages of fraud vs no fraud\n",
    "amount = df.groupby('Is Laundering')['Is Laundering'].sum()\n",
    "fraud, unfraud = len(df[df['Is Laundering'] == 1]), len(df[df['Is Laundering'] == 0])\n",
    "fraud_perc, unfraud_perc = (fraud/len(df)) * 100, (unfraud/len(df))*100\n",
    "\n",
    "Loss = pd.DataFrame({'Fraud' : ['Fraud', 'No Fraud'], 'Total Amount' : [amount[1], amount[0]], 'Freq.' : [fraud, unfraud], '% perc.' : [fraud_perc, unfraud_perc]})\n",
    "\n",
    "Loss = Loss.set_index('Fraud')\n",
    "Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initalise the lists to store catagorical and numerical features\n",
    "catfeat = []\n",
    "numfeat = []\n",
    "\n",
    "for i in df.columns:\n",
    "    if(df[i].dtypes == 'Is Laundering'): catfeat.append(i)\n",
    "    else:\n",
    "        numfeat.append(i)\n",
    "print(f'The number of Objects Features : {len(catfeat)}')\n",
    "print(f'The number of Numerical Features : {len(numfeat)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Number of missing values : {df.isnull().sum().sum()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This scans the data for any duplicates that are within the datasets\n",
    "namedfeat = ['Amount Received', 'Amount Paid', 'Payment Format']\n",
    "for i in df[namedfeat]:\n",
    "    if(df[i].duplicated().sum() > 0): print(f'{i} has {df[i].duplicated().sum()} duplicates') \n",
    "\n",
    "df[namedfeat].describe().T"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description of the data variables"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Percentage Scores\n",
    "This should give a breakdown of the successful percentage amounts for each of the two columns referenced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checks the quality of the withdrawal amounts in the dataset\n",
    "class_counts_with = df['Amount Received'].value_counts()\n",
    "class_counts_percentage_with = df['Amount Received'].value_counts(normalize=True) * 100\n",
    "\n",
    "# Checks the quality of the deposit amounts in the dataset\n",
    "class_counts_dep = df['Amount Paid'].value_counts()\n",
    "class_counts_percentage_dep = df['Amount Paid'].value_counts(normalize=True) * 100\n",
    "\n",
    "print(\"Amount Received: \\n\", class_counts_with)\n",
    "print(\"Amount Paid: \\n\", class_counts_dep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checks the quality of the deposit amounts in the dataset\n",
    "class_counts_lau = df['Is Laundering'].value_counts()\n",
    "class_counts_percentage_lau = df['Is Laundering'].value_counts(normalize=True) * 100\n",
    "\n",
    "print(\"Is Laundering: \\n\", class_counts_lau)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scatter Plot Graphs\n",
    "This will showcase the data as scatter plot graphs, in both 3D and 2D styles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "px.scatter(df, x ='Amount Received', y ='Amount Paid', color ='Payment Format')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "px.scatter(df, x ='Payment Format', y ='Amount Paid', color ='Is Laundering')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "px.scatter_3d(df, x ='Amount Received', y ='Amount Paid', z='Payment Format', color ='Payment Currency')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Read data from csv file\n",
    "data = pd.read_excel(url)\n",
    "\n",
    "# Data to plot\n",
    "labels = data['Payment Format']\n",
    "values = data['Is Laundering']\n",
    "\n",
    "# Plot\n",
    "plt.bar(labels, values)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subset['Amount Paid'] = pd.to_numeric(df_subset['Amount Paid'], errors='coerce')\n",
    "df_subset.boxplot(column='Amount Paid', by='Is Laundering')\n",
    "\n",
    "plt.title('Box plot graph for Payments vs Fraud')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "This will scan through the data, to process the data for allowing training and test data to be created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Read data from csv file\n",
    "data = pd.read_excel(url)\n",
    "\n",
    "# Split the dataset\n",
    "X = df['Is Laundering']\n",
    "y = df['Payment Format']\n",
    "\n",
    "# Plot\n",
    "bars = plt.bar(X, y)\n",
    "plt.bar_label(bars)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2c411529d52bd385a0c5cc81dc7774bf283ab520578901012898b94c5b56fc2a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
